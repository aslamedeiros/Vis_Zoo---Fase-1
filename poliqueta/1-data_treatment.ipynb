{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment (Poliqueta Database)\n",
    "\n",
    "In this notebook I'm doing all the data treatments and adjustments necessary to produce high quality visualizations. \n",
    "\n",
    "This notebook has an output <font color='blue'>treated_db.csv</font> with a subset of the original database properly treated.\n",
    "\n",
    "-----\n",
    "\n",
    "Specifically, for the `poliqueta` database, the files we'll read are <font color='blue'>IBUFRJ27.07.2020 - visualização.xlsx</font> and <font color='blue'>MNRJP27.07.2020 - visualização.xls</font>.\n",
    "\n",
    "<font color='red'>**p.s.:** the idea is to transform all the code in this notebook into a `.py` file with a CLI interface to parse a file and produce a treated csv file right away. </font>\n",
    "\n",
    "is it feasible? as we're selecting plenty different columns... maybe selecting them from a .txt file might be a good solution\n",
    "\n",
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "# IBUFRJ27.07.2020 - visualização.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:17.443453Z",
     "start_time": "2021-01-26T14:40:16.705346Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# quick visualizations for data analytics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# proprietary functions in ./src/MNViz.py\n",
    "from src.MNViz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:18.607586Z",
     "start_time": "2021-01-26T14:40:17.444542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The excel file contains the following sheets: ['Planilha1', 'Planilha2']\n",
      "\n",
      "Database is in sheet: Planilha1\n"
     ]
    }
   ],
   "source": [
    "excel = pd.ExcelFile('./data/IBUFRJ27.07.2020 - visualização.xlsx')\n",
    "sheet_name = excel.sheet_names\n",
    "\n",
    "print('The excel file contains the following sheets:', sheet_name)\n",
    "print('\\nDatabase is in sheet:', sheet_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:22.002716Z",
     "start_time": "2021-01-26T14:40:18.609436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database has 4231 rows and 91 columns.\n"
     ]
    }
   ],
   "source": [
    "db = excel.parse(sheet_name[0], sep=';', encoding='utf-8-sig')\n",
    "poliqueta = db.copy()\n",
    "\n",
    "print(f'The database has {db.shape[0]} rows and {db.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting column names\n",
    "\n",
    "### removing '\\n', '\\t', and other special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:22.006214Z",
     "start_time": "2021-01-26T14:40:22.003926Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta.columns = [str(col).replace(r'\\n','') for col in poliqueta.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T18:51:12.632272Z",
     "start_time": "2020-07-29T18:51:12.627636Z"
    }
   },
   "source": [
    "## Adjusting Determiners and Collectors Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size='5'>**p.s.:** Determiner Last Name 1 contains the FULL name of the Researcher </font>\n",
    "\n",
    "Determiner Last Name 2 is all empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:22.046201Z",
     "start_time": "2021-01-26T14:40:22.007264Z"
    }
   },
   "outputs": [],
   "source": [
    "names_col = ['Collector Last Name 1', 'Collector First Name 1', \n",
    "             'Collector Last Name 2', 'Collector First Name 2', 'Collector Last Name 3', \n",
    "             'Collector First Name 3', 'Collector Last Name 4', 'Collector First Name 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:22.110502Z",
     "start_time": "2021-01-26T14:40:22.047349Z"
    }
   },
   "outputs": [],
   "source": [
    "for name_col in names_col:\n",
    "    if 'last' in name_col.lower():\n",
    "        poliqueta[name_col] = poliqueta[name_col].apply(lambda x: treat_names(x, pos='full'))\n",
    "    else:\n",
    "        poliqueta[name_col] = poliqueta[name_col].apply(treat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T14:40:22.150666Z",
     "start_time": "2021-01-26T14:40:22.111540Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFirstName(name):\n",
    "    name = str(name).split(';')\n",
    "    if len(name) > 1:\n",
    "        return name[0].strip()\n",
    "    elif name[0] == 'nan':\n",
    "        return np.NAN\n",
    "    else:\n",
    "        return name[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:20.787300Z",
     "start_time": "2020-08-29T13:48:20.770339Z"
    }
   },
   "outputs": [],
   "source": [
    "# there's more than one determiner in thar column, so I'm getting only the first one\n",
    "poliqueta['Determiner Last Name 1'] = poliqueta['Determiner Last Name 1'].apply(getFirstName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating column joining First and Last names\n",
    "\n",
    "I'm doing this only for the first collectors and determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:23.853360Z",
     "start_time": "2020-08-29T13:48:23.780892Z"
    }
   },
   "outputs": [],
   "source": [
    "# repteis['DeterminatorFirst_and_LastName'] = repteis['DeterminatorFirstName1'] + ' ' + repteis['DeterminatorLastName1']\n",
    "\n",
    "poliqueta['CollectorFirst_and_LastName'] = poliqueta['Collector First Name 1'] + ' ' + poliqueta['Collector Last Name 1']\n",
    "poliqueta['CollectorFirst_and_LastName2'] = poliqueta['Collector First Name 2'] + ' ' + poliqueta['Collector Last Name 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating taxon columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:25.847263Z",
     "start_time": "2020-08-29T13:48:25.791909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting column Kingdom\n",
      "Adjusting column Phylum 1\n",
      "Adjusting column Class 1\n",
      "Adjusting column Order 1\n",
      "Adjusting column Family 1\n",
      "Adjusting column Genus 1\n",
      "Adjusting column Species 1\n"
     ]
    }
   ],
   "source": [
    "taxon_columns = ['Kingdom', 'Phylum 1', 'Class 1', 'Order 1', 'Family 1', 'Genus 1',\n",
    "                 'Species 1']  # selecting taxonomy columns\n",
    "\n",
    "treat_taxon_columns(poliqueta, taxon_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Genus and Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:28.350374Z",
     "start_time": "2020-08-29T13:48:28.335280Z"
    }
   },
   "outputs": [],
   "source": [
    "# dica da Manoela: epiteto especifico deve ser todo minusculo (especie e subespecie, nesse caso)\n",
    "poliqueta['Species 1'] = poliqueta['Species 1'].str.lower()\n",
    "\n",
    "# genero é escrito com primeira letra maiúscula\n",
    "poliqueta['Genus 1'] = poliqueta['Genus 1'].str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T16:38:50.984971Z",
     "start_time": "2020-08-01T16:38:50.966700Z"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "## adding `Genero` and `Especie`together (they completely identify each animal's species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:29.994630Z",
     "start_time": "2020-08-29T13:48:29.981205Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['genus_and_species'] = poliqueta['Genus 1'] + ' ' + poliqueta['Species 1']\n",
    "\n",
    "poliqueta['genus_and_species'] = poliqueta['genus_and_species'].str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catching Month and Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_columns= ['Cataloged Date','Return Date','Determined date 1', 'Start Date]\n",
    "\n",
    "format: YYYY-mm-dd\n",
    "\n",
    "<font color='red'>Return Date is empty<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:36.651261Z",
     "start_time": "2020-08-29T13:48:36.645991Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetchDate(string):\n",
    "    '''\n",
    "    This function tries to fetch a date (day, month and year) from a string via datetime library. \n",
    "    \n",
    "    If it fails, it'll try to identify these elements from a string in the format YYYY-mm-dd.\n",
    "    '''\n",
    "    string = str(string)\n",
    "    if string.lower() == 'nan':\n",
    "        return (np.NAN, np.NAN)\n",
    "    \n",
    "    try:\n",
    "        date = datetime.datetime.strptime(string, '%Y-%m-%d')\n",
    "        return (date.month, date.year)\n",
    "    \n",
    "    except:\n",
    "        str_list = string.split('-')\n",
    "        year = str_list[0]\n",
    "        month = str_list[1]\n",
    "        \n",
    "        return (month, year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:38.968821Z",
     "start_time": "2020-08-29T13:48:38.723019Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['determined_month'] = poliqueta['Determined date 1'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta['start_month'] = poliqueta['Start Date'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta['cataloged_month'] = poliqueta['Cataloged Date'].apply(lambda x: fetchDate(x)[0])\n",
    "\n",
    "poliqueta['determined_year'] = poliqueta['Determined date 1'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta['start_year'] = poliqueta['Start Date'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta['cataloged_year'] = poliqueta['Cataloged Date'].apply(lambda x: fetchDate(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:40.599832Z",
     "start_time": "2020-08-29T13:48:40.595890Z"
    }
   },
   "outputs": [],
   "source": [
    "def str_with_nan2int(string):\n",
    "    try:\n",
    "        if not np.isnan(string):\n",
    "            return int(string)\n",
    "        else:\n",
    "            return np.NAN\n",
    "    except:\n",
    "        if str(string).lower() == 'nan':\n",
    "            return np.NaN\n",
    "        else:\n",
    "            return int(str(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:41.729857Z",
     "start_time": "2020-08-29T13:48:41.627587Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['determined_month'] = poliqueta['determined_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['start_month'] = poliqueta['start_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['cataloged_month'] = poliqueta['cataloged_month'].apply(str_with_nan2int) #has NaN\n",
    "\n",
    "poliqueta['determined_year'] = poliqueta['determined_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['start_year'] = poliqueta['start_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['cataloged_year'] = poliqueta['cataloged_year'].apply(str_with_nan2int) #has NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Depth` columns\n",
    "\n",
    "<font color='red'>**p.s.:** I'm assuming it's all on the same measure unit (in meters) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:43.550917Z",
     "start_time": "2020-08-29T13:48:43.545578Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['min_depth'] = poliqueta['Min Depth'].astype(float)\n",
    "poliqueta['max_depth'] = poliqueta['Max Depth'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:45.180242Z",
     "start_time": "2020-08-29T13:48:45.166500Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['Latitude'] = poliqueta['Latitude'].apply(convert2float)\n",
    "poliqueta['Longitude'] = poliqueta['Longitude'].apply(convert2float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting locality columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continent\n",
    "WaterBody\n",
    "Country\n",
    "State\n",
    "County\n",
    "Locality Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:49.078452Z",
     "start_time": "2020-08-29T13:48:49.072220Z"
    }
   },
   "outputs": [],
   "source": [
    "# colunas estão boas. Inserir tratamento depois, se necessário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:50.274176Z",
     "start_time": "2020-08-29T13:48:50.269084Z"
    }
   },
   "outputs": [],
   "source": [
    "# inserir depois (Ainda não foi necessário)\n",
    "# poliqueta['Type Status 1'].str.strip().str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Order` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:52.049991Z",
     "start_time": "2020-08-29T13:48:52.044759Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_order(order):\n",
    "    order = str(order)\n",
    "    \n",
    "    if order.lower() == 'nan':\n",
    "        return np.NAN\n",
    "    else:\n",
    "        return order.strip().capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:53.030059Z",
     "start_time": "2020-08-29T13:48:53.014333Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['Order 1'] = poliqueta['Order 1'].apply(correct_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Selecting Subset of Main DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:55.928346Z",
     "start_time": "2020-08-29T13:48:55.916541Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'genero_e_especie_ent', 'genero_e_especie_atual'\n",
    "selected_columns = ['Catalog Number','Cataloged Date','Determined date 1','Start Date',\n",
    "                    'start_year', 'start_month', 'determined_year', 'determined_month',\n",
    "                    'cataloged_month', 'cataloged_year',\n",
    "                    'Class 1','Kingdom', \n",
    "                    'Genus 1', 'Species 1', 'Family 1', 'Phylum 1','Order 1','Type Status 1',\n",
    "                    'Species Author 1', 'Species Author Year 1','Determiner Last Name 1',\n",
    "                    'CollectorFirst_and_LastName', 'CollectorFirst_and_LastName2',\n",
    "                    'Collector First Name 1', 'Collector Last Name 1',\n",
    "                    'Qualifier 1', 'min_depth', 'max_depth',\n",
    "                    'Latitude', 'Longitude', 'Continent',\n",
    "                    'WaterBody', 'Country', 'State', 'County', 'Locality Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:57.412251Z",
     "start_time": "2020-08-29T13:48:57.385035Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable = poliqueta[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "Setting new standardized column names to facilitate future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:58.207667Z",
     "start_time": "2020-08-29T13:48:58.190646Z"
    }
   },
   "outputs": [],
   "source": [
    "renames = {\n",
    "    'Catalog Number':'catalog_number',\n",
    "    'Cataloged Date':'cataloged_date',\n",
    "    'Determined Date 1':'determined_date',\n",
    "    'Class 1':'class',\n",
    "    'Kingdom':'kingdom',\n",
    "    'Genus 1':'genus',\n",
    "    'Species 1':'species',\n",
    "    'Family 1':'family',\n",
    "    'Phylum 1':'phylum',\n",
    "    'Subespecie_atual':'subespecie_atual',\n",
    "    'Type Status 1':'type',\n",
    "    'Order 1':'order',\n",
    "    'Species Author 1':'author',\n",
    "    'Species Author Year 1':'author_year',\n",
    "    'Determiner Last Name 1':'determiner_full_name',\n",
    "    'Collector First Name 1':'collector_first_name',\n",
    "    'Collector Last Name 1':'collector_last_name',\n",
    "    'Qualifier 1':'qualifier',\n",
    "    'Latitude':'lat',\n",
    "    'Longitude':'long', \n",
    "    'Continent':'continent',\n",
    "    'WaterBody':'water_body',\n",
    "    'Country':'country',\n",
    "    'State':'state',\n",
    "    'County':'county',\n",
    "    'Locality Name':'locality',\n",
    "    'CollectorFirst_and_LastName':'collector_full_name',\n",
    "    'CollectorFirst_and_LastName2':'collector_full_name2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:48:59.465258Z",
     "start_time": "2020-08-29T13:48:59.452486Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable = NewTable.rename(columns=renames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exporting to `CSV`\n",
    "\n",
    "name: <font color='blue'>./src/treated_db.csv</font>\n",
    "sep: ';'\n",
    "encoding: 'utf-8-sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:00.378062Z",
     "start_time": "2020-08-29T13:49:00.202552Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable.to_csv('./data/treated_db.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "# MNRJP27.07.2020 - visualização.xls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:03.677674Z",
     "start_time": "2020-08-29T13:49:03.068010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The excel file contains the following sheets: ['Sheet0', 'Planilha1', 'Conferir coordenadas']\n",
      "\n",
      "Database is in sheet: Sheet0\n"
     ]
    }
   ],
   "source": [
    "excel = pd.ExcelFile('./data/MNRJP27.07.2020 - visualização.xls')\n",
    "sheet_name = excel.sheet_names\n",
    "\n",
    "print('The excel file contains the following sheets:', sheet_name)\n",
    "print('\\nDatabase is in sheet:', sheet_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:04.658312Z",
     "start_time": "2020-08-29T13:49:04.457085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database has 2692 rows and 93 columns.\n"
     ]
    }
   ],
   "source": [
    "db = excel.parse(sheet_name[0], sep=';', encoding='utf-8-sig')\n",
    "poliqueta2 = db.copy()\n",
    "\n",
    "print(f'The database has {db.shape[0]} rows and {db.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting column names\n",
    "\n",
    "### removing '\\n', '\\t', and other special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:06.923953Z",
     "start_time": "2020-08-29T13:49:06.913660Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2.columns = [str(col).replace(r'\\n','') for col in poliqueta2.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T18:51:12.632272Z",
     "start_time": "2020-07-29T18:51:12.627636Z"
    }
   },
   "source": [
    "## Adjusting Determiners and Collectors Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size='5'>**p.s.:** Determiner Last Name 1 contains the FULL name of the Researcher </font>\n",
    "\n",
    "Determiner Last Name 2 is all empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:09.144137Z",
     "start_time": "2020-08-29T13:49:09.139962Z"
    }
   },
   "outputs": [],
   "source": [
    "names_col = ['Collector Last Name 1', 'Collector First Name 1', \n",
    "             'Collector Last Name 2', 'Collector First Name 2', 'Collector Last Name 3', \n",
    "             'Collector First Name 3', 'Collector Last Name 4', 'Collector First Name 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:13.494343Z",
     "start_time": "2020-08-29T13:49:13.457517Z"
    }
   },
   "outputs": [],
   "source": [
    "for name_col in names_col:\n",
    "    if 'last' in name_col.lower():\n",
    "        poliqueta2[name_col] = poliqueta2[name_col].apply(lambda x: treat_names(x, pos='full'))\n",
    "    else:\n",
    "        poliqueta2[name_col] = poliqueta2[name_col].apply(treat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:15.058473Z",
     "start_time": "2020-08-29T13:49:15.042268Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['Determiner Last Name1'] = poliqueta2['Determiner Last Name1'].str.strip().str.lower().str.capitalize()\n",
    "poliqueta2['Determiner First Name1'] = poliqueta2['Determiner First Name1'].str.strip().str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating column joining First and Last names\n",
    "\n",
    "I'm doing this only for the first collectors and determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:16.476679Z",
     "start_time": "2020-08-29T13:49:16.458322Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['DeterminerFirst_and_LastName'] = poliqueta2['Determiner First Name1'] + ' ' + poliqueta2['Determiner Last Name1']\n",
    "\n",
    "poliqueta2['CollectorFirst_and_LastName'] = poliqueta2['Collector First Name 1'] + ' ' + poliqueta2['Collector Last Name 1']\n",
    "poliqueta2['CollectorFirst_and_LastName2'] = poliqueta2['Collector First Name 2'] + ' ' + poliqueta2['Collector Last Name 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating taxon columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:18.179221Z",
     "start_time": "2020-08-29T13:49:18.117991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting column Kingdom\n",
      "Adjusting column Phylum 1\n",
      "Adjusting column Class 1\n",
      "Adjusting column Order 1\n",
      "Adjusting column Family 1\n",
      "Adjusting column Genus 1\n",
      "Adjusting column Species 1\n"
     ]
    }
   ],
   "source": [
    "taxon_columns = ['Kingdom', 'Phylum 1', 'Class 1', 'Order 1', 'Family 1', 'Genus 1',\n",
    "                 'Species 1']  # selecting taxonomy columns\n",
    "\n",
    "treat_taxon_columns(poliqueta2, taxon_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Genus and Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:19.683735Z",
     "start_time": "2020-08-29T13:49:19.672464Z"
    }
   },
   "outputs": [],
   "source": [
    "# dica da Manoela: epiteto especifico deve ser todo minusculo (especie e subespecie, nesse caso)\n",
    "poliqueta2['Species 1'] = poliqueta2['Species 1'].str.lower()\n",
    "\n",
    "# gênero é escrito com primeira letra maiúscula\n",
    "poliqueta2['Genus 1'] = poliqueta2['Genus 1'].str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T16:38:50.984971Z",
     "start_time": "2020-08-01T16:38:50.966700Z"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "## adding `Genero` and `Especie`together (they completely identify each animal's species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:20.960543Z",
     "start_time": "2020-08-29T13:49:20.941301Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['genus_and_species'] = poliqueta2['Genus 1'] + ' ' + poliqueta2['Species 1']\n",
    "\n",
    "poliqueta2['genus_and_species'] = poliqueta2['genus_and_species'].str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catching Month and Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_columns= ['Cataloged Date','Return Date','Determined date 1', 'Start Date]\n",
    "\n",
    "format: YYYY-mm-dd\n",
    "\n",
    "<font color='red'>Return Date is empty<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:22.945573Z",
     "start_time": "2020-08-29T13:49:22.940708Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetchDate(string):\n",
    "    '''\n",
    "    This function tries to fetch a date (day, month and year) from a string via datetime library. \n",
    "    \n",
    "    If it fails, it'll try to identify these elements from a string in the format YYYY-mm-dd.\n",
    "    '''\n",
    "    string = str(string)\n",
    "    if string.lower() == 'nan':\n",
    "        return (np.NAN, np.NAN)\n",
    "    \n",
    "    try:\n",
    "        date = datetime.datetime.strptime(string, '%Y-%m-%d')\n",
    "        return (date.month, date.year)\n",
    "    \n",
    "    except:\n",
    "        str_list = string.split('-')\n",
    "        year = str_list[0]\n",
    "        month = str_list[1]\n",
    "        \n",
    "        return (month, year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:24.589173Z",
     "start_time": "2020-08-29T13:49:24.405391Z"
    }
   },
   "outputs": [],
   "source": [
    "# poliqueta2['determined_month'] = poliqueta2['Determined date 1'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta2['start_month'] = poliqueta2['Start Date'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta2['cataloged_month'] = poliqueta2['Cataloged Date'].apply(lambda x: fetchDate(x)[0])\n",
    "\n",
    "# poliqueta['determined_year'] = poliqueta['Determined date 1'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta2['start_year'] = poliqueta2['Start Date'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta2['cataloged_year'] = poliqueta2['Cataloged Date'].apply(lambda x: fetchDate(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:25.307868Z",
     "start_time": "2020-08-29T13:49:25.296627Z"
    }
   },
   "outputs": [],
   "source": [
    "def str_with_nan2int(string):\n",
    "    try:\n",
    "        if not np.isnan(string):\n",
    "            return int(string)\n",
    "        else:\n",
    "            return np.NAN\n",
    "    except:\n",
    "        if str(string).lower() == 'nan':\n",
    "            return np.NaN\n",
    "        else:\n",
    "            return int(str(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:26.872060Z",
     "start_time": "2020-08-29T13:49:26.835308Z"
    }
   },
   "outputs": [],
   "source": [
    "# poliqueta2['determined_month'] = poliqueta2['determined_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta2['start_month'] = poliqueta2['start_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta2['cataloged_month'] = poliqueta2['cataloged_month'].apply(str_with_nan2int) #has NaN\n",
    "\n",
    "# poliqueta2['determined_year'] = poliqueta2['determined_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta2['start_year'] = poliqueta2['start_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta2['cataloged_year'] = poliqueta2['cataloged_year'].apply(str_with_nan2int) #has NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Depth` columns\n",
    "\n",
    "<font color='red'>**p.s.:** I'm assuming it's all on the same measure unit (in meters) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:27.814720Z",
     "start_time": "2020-08-29T13:49:27.803573Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['min_depth'] = poliqueta2['Min Depth'].astype(float)\n",
    "poliqueta2['max_depth'] = poliqueta2['Max Depth'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:29.607490Z",
     "start_time": "2020-08-29T13:49:29.592503Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['Latitude'] = poliqueta2['Latitude1'].apply(convert2float)\n",
    "poliqueta2['Longitude'] = poliqueta2['Longitude1'].apply(convert2float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting locality columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continent\n",
    "WaterBody\n",
    "Country\n",
    "State\n",
    "County\n",
    "Locality Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:30.973519Z",
     "start_time": "2020-08-29T13:49:30.964830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Depth\n",
      "Max Depth\n",
      "min_depth\n",
      "max_depth\n"
     ]
    }
   ],
   "source": [
    "for col in poliqueta2.columns:\n",
    "    if 'depth' in col.lower():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### treating continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:32.890726Z",
     "start_time": "2020-08-29T13:49:32.886997Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_continent(string):\n",
    "    string = str(string)\n",
    "\n",
    "    continent_correction = {\n",
    "        'America Central':'Central America',\n",
    "        'Asia Oriental':'Asia',  # there's just one register of Asia Oriental\n",
    "        'European':'Europe',\n",
    "    }\n",
    "    \n",
    "    if string in continent_correction.keys():\n",
    "        return continent_correction[string]  # returns corrected continent\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:34.582565Z",
     "start_time": "2020-08-29T13:49:34.566168Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['Continent'] = poliqueta2['Continent'].str.strip().apply(correct_continent).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### treating State column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:35.721943Z",
     "start_time": "2020-08-29T13:49:35.711688Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_accents(string):\n",
    "    string = str(string).strip()\n",
    "    \n",
    "    return unidecode.unidecode(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:36.280214Z",
     "start_time": "2020-08-29T13:49:36.210004Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['State'] = poliqueta2['State'].str.strip().apply(remove_accents).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:37.647084Z",
     "start_time": "2020-08-29T13:49:37.643540Z"
    }
   },
   "outputs": [],
   "source": [
    "# other columns will remain the same, while further treatment doesn't seem necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:38.322873Z",
     "start_time": "2020-08-29T13:49:38.320448Z"
    }
   },
   "outputs": [],
   "source": [
    "# inserir depois (Ainda não foi necessário)\n",
    "# poliqueta['Type Status 1'].str.strip().str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Order` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:39.835953Z",
     "start_time": "2020-08-29T13:49:39.830426Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_order(order):\n",
    "    order = str(order)\n",
    "    \n",
    "    if order.lower() == 'nan':\n",
    "        return np.NAN\n",
    "    else:\n",
    "        return order.strip().capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:41.534326Z",
     "start_time": "2020-08-29T13:49:41.525153Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta2['Order 1'] = poliqueta2['Order 1'].apply(correct_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Selecting Subset of Main DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:43.003750Z",
     "start_time": "2020-08-29T13:49:42.993112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Não tem Determined Date\n",
    "selected_columns = ['Catalog Number','Cataloged Date','Start Date',\n",
    "                    'start_year', 'start_month',\n",
    "                    'cataloged_month', 'cataloged_year',\n",
    "                    'Class 1','Kingdom', \n",
    "                    'Genus 1', 'Species 1', 'Family 1', 'Phylum 1','Order 1','Type Status 1',\n",
    "                    'Species Author 1', 'Species Author Year 1','Determiner Last Name1','Determiner First Name1',\n",
    "                    'DeterminerFirst_and_LastName','CollectorFirst_and_LastName','CollectorFirst_and_LastName2', \n",
    "                    'Collector First Name 1', 'Collector Last Name 1',\n",
    "                    'Qualifier 1', 'min_depth', 'max_depth',\n",
    "                    'Latitude', 'Longitude', 'Continent',\n",
    "                    'WaterBody', 'Country', 'State', 'County', 'Locality Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:44.763124Z",
     "start_time": "2020-08-29T13:49:44.741221Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable2 = poliqueta2[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "Setting new standardized column names to facilitate future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:46.224884Z",
     "start_time": "2020-08-29T13:49:46.219898Z"
    }
   },
   "outputs": [],
   "source": [
    "renames = {\n",
    "    'Catalog Number':'catalog_number',\n",
    "    'Cataloged Date':'cataloged_date',\n",
    "    'Determined Date 1':'determined_date',\n",
    "    'Class 1':'class',\n",
    "    'Kingdom':'kingdom',\n",
    "    'Genus 1':'genus',\n",
    "    'Species 1':'species',\n",
    "    'Family 1':'family',\n",
    "    'Phylum 1':'phylum',\n",
    "    'Subespecie_atual':'subespecie_atual',\n",
    "    'Type Status 1':'type',\n",
    "    'Order 1':'order',\n",
    "    'Species Author 1':'author',\n",
    "    'Species Author Year 1':'author_year',\n",
    "    'Determiner Last Name1':'determiner_last_name',\n",
    "    'Determiner First Name1':'determiner_first_name',\n",
    "    'Collector First Name 1':'collector_first_name',\n",
    "    'Collector Last Name 1':'collector_last_name',\n",
    "    'Qualifier 1':'qualifier',\n",
    "    'Latitude':'lat',\n",
    "    'Longitude':'long', \n",
    "    'Continent':'continent',\n",
    "    'WaterBody':'water_body',\n",
    "    'Country':'country',\n",
    "    'State':'state',\n",
    "    'County':'county',\n",
    "    'Locality Name':'locality',\n",
    "    'CollectorFirst_and_LastName':'collector_full_name',\n",
    "    'CollectorFirst_and_LastName2':'collector_full_name2',\n",
    "    'DeterminerFirst_and_LastName':'determiner_full_name'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:47.627400Z",
     "start_time": "2020-08-29T13:49:47.620351Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable2 = NewTable2.rename(columns=renames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exporting to `CSV`\n",
    "\n",
    "name: <font color='blue'>./src/treated_db.csv</font>\n",
    "sep: ';'\n",
    "encoding: 'utf-8-sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:53.931551Z",
     "start_time": "2020-08-29T13:49:53.819586Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable2.to_csv('./data/treated_db2.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "<br>\n",
    "\n",
    "# Merging both databases\n",
    "\n",
    "p.s.: this will represent the whole 'poliqueta' collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:55.748015Z",
     "start_time": "2020-08-29T13:49:55.737994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Determined date 1', 'determined_month', 'determined_year'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge NewTable and NewTable2\n",
    "set(NewTable.columns).difference(set(NewTable2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:56.943331Z",
     "start_time": "2020-08-29T13:49:56.919037Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_table = pd.concat([NewTable, NewTable2], join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:57.759365Z",
     "start_time": "2020-08-29T13:49:57.755370Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_prefix(catalog):\n",
    "    catalog = str(catalog)\n",
    "    \n",
    "    if 'IBUFRJ' in catalog.upper():\n",
    "        return 'IBUFRJ'\n",
    "    elif 'MNRJP' in catalog.upper():\n",
    "        return 'MNRJP'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:58.554348Z",
     "start_time": "2020-08-29T13:49:58.535305Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating column collection_prefix IBUFRJ and MNRJP (to identify origin of that info.)\n",
    "merged_table['collection_prefix'] = merged_table['catalog_number'].apply(create_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:49:59.569286Z",
     "start_time": "2020-08-29T13:49:59.372966Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_table.to_csv('./data/merged_db.csv', sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
