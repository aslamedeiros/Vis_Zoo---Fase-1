{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment (Poliqueta Database)\n",
    "\n",
    "In this notebook I'm doing all the data treatments and adjustments necessary to produce high quality visualizations. \n",
    "\n",
    "This notebook has an output <font color='blue'>treated_db.csv</font> with a subset of the original database properly treated.\n",
    "\n",
    "-----\n",
    "\n",
    "Specifically, for the `poliqueta` database, the files we'll read are <font color='blue'>IBUFRJ27.07.2020 - visualização.xlsx</font> and <font color='blue'>MNRJP27.07.2020 - visualização.xls</font>.\n",
    "\n",
    "<font color='red'>**p.s.:** the idea is to transform all the code in this notebook into a `.py` file with a CLI interface to parse a file and produce a treated csv file right away. </font>\n",
    "\n",
    "is it feasible? as we're selecting plenty different columns... maybe selecting them from a .txt file might be a good solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:02.865210Z",
     "start_time": "2020-08-03T11:06:02.858621Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# quick visualizations for data analytics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# proprietary functions in ./src/MNViz.py\n",
    "from src.MNViz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:06.979171Z",
     "start_time": "2020-08-03T11:06:02.872473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The excel file contains the following sheets: ['Planilha1', 'Planilha2']\n",
      "\n",
      "Database is in sheet: Planilha1\n"
     ]
    }
   ],
   "source": [
    "excel = pd.ExcelFile('./data/IBUFRJ27.07.2020 - visualização.xlsx')\n",
    "sheet_name = excel.sheet_names\n",
    "\n",
    "print('The excel file contains the following sheets:', sheet_name)\n",
    "print('\\nDatabase is in sheet:', sheet_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.288562Z",
     "start_time": "2020-08-03T11:06:06.982613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database has 4231 rows and 91 columns.\n"
     ]
    }
   ],
   "source": [
    "db = excel.parse(sheet_name[0], sep=';', encoding='utf-8-sig')\n",
    "poliqueta = db.copy()\n",
    "\n",
    "print(f'The database has {db.shape[0]} rows and {db.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting column names\n",
    "\n",
    "### removing '\\n', '\\t', and other special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.295297Z",
     "start_time": "2020-08-03T11:06:07.291367Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta.columns = [str(col).replace(r'\\n','') for col in poliqueta.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T18:51:12.632272Z",
     "start_time": "2020-07-29T18:51:12.627636Z"
    }
   },
   "source": [
    "## Adjusting Determiners and Collectors Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size='5'>**p.s.:** Determiner Last Name 1 contains the FULL name of the Researcher </font>\n",
    "\n",
    "Determiner Last Name 2 is all empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.381595Z",
     "start_time": "2020-08-03T11:06:07.297645Z"
    }
   },
   "outputs": [],
   "source": [
    "names_col = ['Collector Last Name 1', 'Collector First Name 1', \n",
    "             'Collector Last Name 2', 'Collector First Name 2', 'Collector Last Name 3', \n",
    "             'Collector First Name 3', 'Collector Last Name 4', 'Collector First Name 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.499592Z",
     "start_time": "2020-08-03T11:06:07.385326Z"
    }
   },
   "outputs": [],
   "source": [
    "for name_col in names_col:\n",
    "    if 'last' in name_col.lower():\n",
    "        poliqueta[name_col] = poliqueta[name_col].apply(lambda x: treat_names(x, pos='last'))\n",
    "    else:\n",
    "        poliqueta[name_col] = poliqueta[name_col].apply(treat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.582683Z",
     "start_time": "2020-08-03T11:06:07.501285Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFirstName(name):\n",
    "    name = str(name).split(';')\n",
    "    if len(name) > 1:\n",
    "        return name[0].strip()\n",
    "    elif name[0] == 'nan':\n",
    "        return np.NAN\n",
    "    else:\n",
    "        return name[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.674606Z",
     "start_time": "2020-08-03T11:06:07.586479Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['Determiner Last Name 1'] = poliqueta['Determiner Last Name 1'].apply(getFirstName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating column joining First and Last names\n",
    "\n",
    "I'm doing this only for the first collectors and determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.764434Z",
     "start_time": "2020-08-03T11:06:07.676475Z"
    }
   },
   "outputs": [],
   "source": [
    "# repteis['DeterminatorFirst_and_LastName'] = repteis['DeterminatorFirstName1'] + ' ' + repteis['DeterminatorLastName1']\n",
    "\n",
    "poliqueta['CollectorFirst_and_LastName'] = poliqueta['Collector First Name 1'] + ' ' + poliqueta['Collector Last Name 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating taxon columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.872309Z",
     "start_time": "2020-08-03T11:06:07.770467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting column Kingdom\n",
      "Adjusting column Phylum 1\n",
      "Adjusting column Class 1\n",
      "Adjusting column Order 1\n",
      "Adjusting column Family 1\n",
      "Adjusting column Genus 1\n",
      "Adjusting column Species 1\n"
     ]
    }
   ],
   "source": [
    "taxon_columns = ['Kingdom', 'Phylum 1', 'Class 1', 'Order 1', 'Family 1', 'Genus 1',\n",
    "                 'Species 1']  # selecting taxonomy columns\n",
    "\n",
    "treat_taxon_columns(poliqueta, taxon_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Genus and Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:07.921633Z",
     "start_time": "2020-08-03T11:06:07.875565Z"
    }
   },
   "outputs": [],
   "source": [
    "# dica da Manoela: epiteto especifico deve ser todo minusculo (especie e subespecie, nesse caso)\n",
    "poliqueta['Species 1'] = poliqueta['Species 1'].str.lower()\n",
    "poliqueta['Genus 1'] = poliqueta['Genus 1'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T16:38:50.984971Z",
     "start_time": "2020-08-01T16:38:50.966700Z"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "## adding `Genero` and `Especie`together (they completely identify each animal's species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.031808Z",
     "start_time": "2020-08-03T11:06:07.923298Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['genus_and_species'] = poliqueta['Genus 1'] + ' ' + poliqueta['Species 1']\n",
    "\n",
    "poliqueta['genus_and_species'] = poliqueta['genus_and_species'].str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catching Month and Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_columns= ['Cataloged Date','Return Date','Determined date 1', 'Start Date]\n",
    "\n",
    "format: YYYY-mm-dd\n",
    "\n",
    "<font color='red'>Return Date is empty<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.103558Z",
     "start_time": "2020-08-03T11:06:08.033831Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetchDate(string):\n",
    "    '''\n",
    "    This function tries to fetch a date (day, month and year) from a string via datetime library. \n",
    "    \n",
    "    If it fails, it'll try to identify these elements from a string in the format YYYY-mm-dd.\n",
    "    '''\n",
    "    string = str(string)\n",
    "    if string.lower() == 'nan':\n",
    "        return (np.NAN, np.NAN)\n",
    "    \n",
    "    try:\n",
    "        date = datetime.datetime.strptime(string, '%Y-%m-%d')\n",
    "        return (date.month, date.year)\n",
    "    \n",
    "    except:\n",
    "        str_list = string.split('-')\n",
    "        year = str_list[0]\n",
    "        month = str_list[1]\n",
    "        \n",
    "        return (month, year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.222009Z",
     "start_time": "2020-08-03T11:06:08.107296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    941\n",
       "NaN     882\n",
       "1998    486\n",
       "2001    296\n",
       "2014    237\n",
       "2003    200\n",
       "2002    178\n",
       "2011    173\n",
       "2008    157\n",
       "2005    131\n",
       "2013    123\n",
       "2009    120\n",
       "2012    101\n",
       "1997     47\n",
       "2015     24\n",
       "2007     20\n",
       "1993     18\n",
       "1996     17\n",
       "2006     16\n",
       "1994     11\n",
       "2004     10\n",
       "1984      5\n",
       "1905      5\n",
       "1986      4\n",
       "1967      4\n",
       "1999      3\n",
       "1980      3\n",
       "1992      3\n",
       "2010      2\n",
       "1979      2\n",
       "1971      2\n",
       "1966      2\n",
       "2009      1\n",
       "2005      1\n",
       "2007      1\n",
       "1977      1\n",
       "1961      1\n",
       "1983      1\n",
       "1991      1\n",
       "1982      1\n",
       "Name: Start Date, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poliqueta['Start Date'].apply(lambda x: fetchDate(x)[1]).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.462050Z",
     "start_time": "2020-08-03T11:06:08.224388Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['determined_month'] = poliqueta['Determined date 1'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta['start_month'] = poliqueta['Start Date'].apply(lambda x: fetchDate(x)[0])\n",
    "poliqueta['cataloged_month'] = poliqueta['Cataloged Date'].apply(lambda x: fetchDate(x)[0])\n",
    "\n",
    "poliqueta['determined_year'] = poliqueta['Determined date 1'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta['start_year'] = poliqueta['Start Date'].apply(lambda x: fetchDate(x)[1])\n",
    "poliqueta['cataloged_year'] = poliqueta['Cataloged Date'].apply(lambda x: fetchDate(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.470572Z",
     "start_time": "2020-08-03T11:06:08.464760Z"
    }
   },
   "outputs": [],
   "source": [
    "def str_with_nan2int(string):\n",
    "    try:\n",
    "        if not np.isnan(string):\n",
    "            return int(string)\n",
    "        else:\n",
    "            return np.NAN\n",
    "    except:\n",
    "        if str(string).lower() == 'nan':\n",
    "            return np.NaN\n",
    "        else:\n",
    "            return int(str(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.608966Z",
     "start_time": "2020-08-03T11:06:08.472618Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['determined_month'] = poliqueta['determined_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['start_month'] = poliqueta['start_month'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['cataloged_month'] = poliqueta['cataloged_month'].apply(str_with_nan2int) #has NaN\n",
    "\n",
    "poliqueta['determined_year'] = poliqueta['determined_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['start_year'] = poliqueta['start_year'].apply(str_with_nan2int) #has NaN\n",
    "poliqueta['cataloged_year'] = poliqueta['cataloged_year'].apply(str_with_nan2int) #has NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Depth` columns\n",
    "\n",
    "<font color='red'>**p.s.:** I'm assuming it's all on the same measure unit (in meters) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.699548Z",
     "start_time": "2020-08-03T11:06:08.610775Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['min_depth'] = poliqueta['Min Depth'].astype(float)\n",
    "poliqueta['max_depth'] = poliqueta['Max Depth'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.798315Z",
     "start_time": "2020-08-03T11:06:08.702221Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['Latitude'] = poliqueta['Latitude'].apply(convert2float)\n",
    "poliqueta['Longitude'] = poliqueta['Longitude'].apply(convert2float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting locality columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continent\n",
    "WaterBody\n",
    "Country\n",
    "State\n",
    "County\n",
    "Locality Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.889035Z",
     "start_time": "2020-08-03T11:06:08.800003Z"
    }
   },
   "outputs": [],
   "source": [
    "# colunas estão boas. Inserir tratamento depois, se necessário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:08.967576Z",
     "start_time": "2020-08-03T11:06:08.891517Z"
    }
   },
   "outputs": [],
   "source": [
    "# inserir depois (Ainda não foi necessário)\n",
    "# poliqueta['Type Status 1'].str.strip().str.lower().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Adjusting `Ordem` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.045967Z",
     "start_time": "2020-08-03T11:06:08.970102Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_order(order):\n",
    "    order = str(order)\n",
    "    \n",
    "    if order.lower() == 'nan':\n",
    "        return np.NAN\n",
    "    else:\n",
    "        return order.strip().capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.129727Z",
     "start_time": "2020-08-03T11:06:09.049283Z"
    }
   },
   "outputs": [],
   "source": [
    "poliqueta['Order 1'] = poliqueta['Order 1'].apply(correct_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Selecting Subset of Main DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.200972Z",
     "start_time": "2020-08-03T11:06:09.132535Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'genero_e_especie_ent', 'genero_e_especie_atual'\n",
    "selected_columns = ['Catalog Number','Cataloged Date','Determined date 1','Start Date',\n",
    "                    'start_year', 'start_month', 'determined_year', 'determined_month',\n",
    "                    'cataloged_month', 'cataloged_year',\n",
    "                    'Class 1','Kingdom', \n",
    "                    'Genus 1', 'Species 1', 'Family 1', 'Phylum 1','Order 1','Type Status 1',\n",
    "                    'Species Author 1', 'Species Author Year 1','Determiner Last Name 1',\n",
    "                    'CollectorFirst_and_LastName', 'Collector First Name 1', 'Collector Last Name 1',\n",
    "                    'Qualifier 1', 'min_depth', 'max_depth',\n",
    "                    'Latitude', 'Longitude', 'Continent',\n",
    "                    'WaterBody', 'Country', 'State', 'County', 'Locality Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.326300Z",
     "start_time": "2020-08-03T11:06:09.203070Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable = poliqueta[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "Setting new standardized column names to facilitate future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.398197Z",
     "start_time": "2020-08-03T11:06:09.328306Z"
    }
   },
   "outputs": [],
   "source": [
    "renames = {\n",
    "    'Catalog Number':'catalog_number',\n",
    "    'Cataloged Date':'cataloged_date',\n",
    "    'Determined Date 1':'determined_date',\n",
    "    'Class 1':'class',\n",
    "    'Kingdom':'kingdom',\n",
    "    'Genus 1':'genus',\n",
    "    'Species 1':'species',\n",
    "    'Family 1':'family',\n",
    "    'Phylum 1':'phylum',\n",
    "    'Subespecie_atual':'subespecie_atual',\n",
    "    'Type Status 1':'type',\n",
    "    'Order 1':'order',\n",
    "    'Species Author 1':'author',\n",
    "    'Species Author Year 1':'author_year',\n",
    "    'Determiner Last Name 1':'determiner_full_name',\n",
    "    'Collector First Name 1':'collector_first_name',\n",
    "    'Collector Last Name 1':'collector_last_name',\n",
    "    'Qualifier 1':'qualifier',\n",
    "    'Latitude':'lat',\n",
    "    'Longitude':'long', \n",
    "    'Continent':'continent',\n",
    "    'WaterBody':'water_body',\n",
    "    'Country':'country',\n",
    "    'State':'state',\n",
    "    'County':'county',\n",
    "    'Locality Name':'locality',\n",
    "    'CollectorFirst_and_LastName':'collector_full_name'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.481142Z",
     "start_time": "2020-08-03T11:06:09.403160Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable = NewTable.rename(columns=renames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exporting to `CSV`\n",
    "\n",
    "name: <font color='blue'>./src/treated_db.csv</font>\n",
    "sep: ';'\n",
    "encoding: 'utf-8-sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T11:06:09.673652Z",
     "start_time": "2020-08-03T11:06:09.493053Z"
    }
   },
   "outputs": [],
   "source": [
    "NewTable.to_csv('./data/treated_db.csv', sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:viz] *",
   "language": "python",
   "name": "conda-env-viz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
